{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/76kr/BcF/cx78/1Mqevi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harish18010/pdf_summerizer/blob/main/PDF_Summerizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1TnVj8y-K5M"
      },
      "outputs": [],
      "source": [
        "!pip install transformers  pymupdf torch gtts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import re\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "jl1UBICqH2m6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from gtts import gTTS\n",
        "import os\n",
        "def save_tts(text, filename, lang='en'):\n",
        "    tts = gTTS(text=text, lang=lang)\n",
        "    tts.save(filename)\n",
        "    print(f\" Audio summary saved as {filename}\")\n"
      ],
      "metadata": {
        "id": "HOfaWwx3aEb8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Use shift or ctrl to select multiple files\n",
        "pdf_files = list(uploaded.keys())\n",
        "print(\"Uploaded files:\", pdf_files)"
      ],
      "metadata": {
        "id": "hV5GDdzC-o0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_and_clean_text(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        page_text = page.get_text()\n",
        "        text += page_text + \"\\n\"\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "9UiGwKXC_6pC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, max_chunk_len=1000):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + max_chunk_len\n",
        "        if end >= len(text):\n",
        "            chunks.append(text[start:])\n",
        "            break\n",
        "        last_period = text.rfind('.', start, end)\n",
        "        if last_period == -1 or last_period <= start:\n",
        "            last_period = end-1\n",
        "        chunks.append(text[start:last_period+1].strip())\n",
        "        start = last_period + 1\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "4LN06uQkI48r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_summarizer(model_name=\"facebook/bart-large-cnn\",device=-1):\n",
        "    return pipeline(\"summarization\", model=model_name,device=device)"
      ],
      "metadata": {
        "id": "b5aNFdB7DPY0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_with_mode(text, summarizer, mode=\"brief\"):\n",
        "    if mode == \"brief\":\n",
        "        max_len, min_len = 80, 30\n",
        "    elif mode == \"detailed\":\n",
        "        max_len, min_len = 200, 100\n",
        "    elif mode == \"bullet\":\n",
        "        max_len, min_len = 150, 70\n",
        "    else:\n",
        "        # fallback default\n",
        "        max_len, min_len = 150, 50\n",
        "\n",
        "    # Summarize the text\n",
        "    summary = summarizer(text, max_length=max_len, min_length=min_len, do_sample=False)[0]['summary_text']\n",
        "\n",
        "    # If bullet mode is selected, it converts sentences to bullet points\n",
        "    if mode == \"bullet\":\n",
        "        # Simple split by '. ' to create bullets, adjust as needed\n",
        "        sentences = [s.strip() for s in summary.split('. ') if s]\n",
        "        bullet_summary = \"\\n\".join([f\"• {s}.\" if not s.endswith('.') else f\"• {s}\" for s in sentences])\n",
        "        return bullet_summary\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "EENL1ENEWUhM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_stage_summarize_with_mode(text, summarizer, mode=\"brief\", max_chunk_len=1000, group_size=2, final_chunk_threshold=8):\n",
        "    chunks = chunk_text(text, max_chunk_len=max_chunk_len)\n",
        "    print(f\" Stage 1: Summarizing {len(chunks)} chunks in '{mode}' mode...\")\n",
        "\n",
        "    chunk_summaries = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\" Summarizing chunk {i+1}/{len(chunks)}...\")\n",
        "        summary = summarize_with_mode(chunk, summarizer, mode=mode)\n",
        "        chunk_summaries.append(summary)\n",
        "\n",
        "    # Group summaries as paragraphs\n",
        "    grouped_paragraphs = []\n",
        "    for i in range(0, len(chunk_summaries), group_size):\n",
        "        group = chunk_summaries[i:i+group_size]\n",
        "        paragraph = \"\\n\\n\".join(group)\n",
        "        grouped_paragraphs.append(paragraph)\n",
        "\n",
        "    formatted_summary = \"\\n\\n\".join(grouped_paragraphs)\n",
        "\n",
        "    if len(grouped_paragraphs) > final_chunk_threshold:\n",
        "        print(\" Too many chunks — returning paragraph-formatted summary only.\")\n",
        "        return formatted_summary\n",
        "    else:\n",
        "        print(\" Final summarization stage...\")\n",
        "        final_chunks = chunk_text(formatted_summary, max_chunk_len=800)\n",
        "        final_summaries = []\n",
        "        for i, chunk in enumerate(final_chunks):\n",
        "            print(f\" Final summarizing chunk {i+1}/{len(final_chunks)}...\")\n",
        "            summary = summarize_with_mode(chunk, summarizer, mode=mode)\n",
        "            final_summaries.append(summary)\n",
        "\n",
        "        return \"\\n\\n\".join(final_summaries)\n"
      ],
      "metadata": {
        "id": "sn9T_rqrWnH_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load summarizer\n",
        "import torch\n",
        "\n",
        "try:\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    summarizer = get_summarizer(device=device)\n",
        "\n",
        "except RuntimeError:\n",
        "    print(\" GPU error. Falling back to smaller model on CPU.\")\n",
        "    summarizer = get_summarizer( model=\"sshleifer/distilbart-cnn-12-6\", device=-1)\n",
        "\n",
        "# Summarize text using multi-stage approach\n",
        "for pdf_path in pdf_files:\n",
        "    print(f\"\\n Processing: {pdf_path}\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        text = extract_and_clean_text(pdf_path)\n",
        "    except Exception as e:\n",
        "        print(f\" Error reading {pdf_path}: {e}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    if not text.strip():\n",
        "        print(f\" No text found in {pdf_path}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(\"Starting summarization...\")\n",
        "    mode_choice = input(\"Choose summarization mode (brief/detailed/bullet): \").strip().lower()\n",
        "    if mode_choice not in [\"brief\", \"detailed\", \"bullet\"]:\n",
        "        print(\"Invalid mode choice, defaulting to 'brief'.\")\n",
        "        mode_choice = \"brief\"\n",
        "\n",
        "\n",
        "    summary = multi_stage_summarize_with_mode(text, summarizer, mode=mode_choice)\n",
        "\n",
        "    print(summary)\n",
        "\n",
        "    base_name = pdf_path.rsplit('.', 1)[0]\n",
        "    summary_filename = f\"{base_name}_summary.txt\"\n",
        "    with open(summary_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    print(f\" Summary saved as: {summary_filename}\")\n",
        "    files.download(summary_filename)\n",
        "    generate_audio = input(\"Do you want to generate audio summaries? (y/n): \").strip().lower() == 'y'\n",
        "    if generate_audio:\n",
        "\n",
        "        audio_filename = f\"{base_name}_summary.mp3\"\n",
        "        save_tts(summary, audio_filename)\n",
        "        files.download(audio_filename)"
      ],
      "metadata": {
        "id": "fR3uROktJVCt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
